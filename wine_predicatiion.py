# -*- coding: utf-8 -*-
"""wine -predicatiion

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y3Dyu4dVc95gIF7ThglxveyqW2sE_xoA

# 🧪 Wine Quality Prediction: Classifying Good vs Not Good Wine
### Using Logistic Regression and Feature Analysis on White Wine Data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# IMPORT DATA FROM CSV FILE"""

white=pd.read_csv("/content/winequality-white.csv",sep=";")

"""## 📄 Preview of the White Wine Dataset
The first 5 rows of the dataset using `white.head()`:

"""

white.head()

"""## 🔍 Last 5 Rows of the Dataset
Displayed using `white.tail()` to inspect the end of the dataset.

"""

white.tail()

"""## 📊 Statistical Summary of the Dataset
Using `white.describe()` to view basic statistics for each numeric column (mean, std, min, max, quartiles).



"""

white.describe()

"""## ❓ Missing Values Check
Using `white.isnull().sum()` to identify columns with null or missing data.

"""

white.isnull().sum()

"""## 🧾 First 5 Rows of the Dataset
Previewing the first few entries using `white.head()` to understand the structure and sample data.

"""

white.head()

"""## 🔗 Correlation Matrix
The correlation matrix helps identify relationships between numeric features. Positive values indicate direct relationships, while negative values show inverse relationships.

"""

j=white.corr()
j

"""## 📌 Heatmap of Feature Correlations
Visualizing the correlation matrix using a heatmap to better understand the relationships between variables. Darker colors represent stronger correlations.



"""

plt.figure(figsize=(10, 8))
sns.heatmap(j, annot=True, cmap='coolwarm', linewidths=0.5)
plt.show()

"""## 🎯 Correlation with Wine Quality
Sorting features by their correlation with the `quality` column to identify which ones are most relevant for predicting wine quality.

"""

# Sort correlations with respect to 'quality'
quality_corr = j['quality'].sort_values(ascending=False)
print(quality_corr)

"""## 🚫 Dropping Columns with Low Correlation to Quality
We drop features with weak correlations to the target variable `quality` to improve model performance and reduce noise. The following columns are removed:
- `free sulfur dioxide`
- `citric acid`
- `residual sugar`
- `pH`
- `sulphates`
- `fixed acidity`

"""

low_corr_columns = [
    'free sulfur dioxide',
    'citric acid',
    'residual sugar',
    'pH',
    'sulphates',
    'fixed acidity'
]

white.drop(columns=low_corr_columns, inplace=True)

"""## 🔄 Correlation Matrix After Dropping Low-Correlation Features
We recalculate the correlation matrix to observe how the remaining features correlate with each other and with the target `quality`.

"""

after=white.corr()
after

"""## 📊 Updated Heatmap of Feature Correlations
Visualizing the correlation matrix after removing low-correlation features to observe the relationships between the remaining variables and `quality`.

"""

plt.figure(figsize=(10, 8))
sns.heatmap(after, annot=True, cmap='coolwarm', linewidths=0.5)
plt.show()

"""## 🎯 Sorted Feature Correlations with Quality (Updated)
Sorting the remaining features by their correlation with the `quality` column after removing low-correlation features to identify the most relevant predictors for wine quality.

"""

# Sort correlations with respect to 'quality'
quality_corr = after['quality'].sort_values(ascending=False)
print(quality_corr)

"""## ✅ Selecting Relevant Features for Model Training
Based on the correlation analysis, we select the most relevant features for predicting wine quality. These are:
- `alcohol`
- `density`
- `volatile acidity`
- `chlorides`
- `total sulfur dioxide`
- `quality` (target variable)

"""

# Select useful columns
columns = ['alcohol', 'density', 'volatile acidity', 'chlorides', 'total sulfur dioxide', 'quality']
white_corr = white[columns]

"""## 📊 Boxplots of Features vs. Wine Quality
We use boxplots to visually inspect how each feature varies across different wine quality levels. This helps identify any potential trends or outliers.

"""

# 2. Boxplots of each feature vs. quality

for col in columns:
    if col != 'quality':
        plt.figure(figsize=(6, 4))
        sns.boxplot(x='quality', y=col, data=white_corr)
        plt.title(f'{col} vs Wine Quality')
        plt.show()

"""## 🔄 Pairplot of Features vs. Wine Quality
A pairplot helps visualize the relationships between pairs of features, with colors indicating different wine quality levels. This allows us to identify any potential correlations or patterns between features.

"""

# 3. Pairplot
sns.pairplot(white_corr, hue='quality', diag_kind='kde', palette='Set2')
plt.suptitle('Pairwise Relationships', y=1.02)
plt.show()

"""## 📊 Boxplots of All Numeric Features
Visualizing boxplots for all numeric features to check for any outliers and to understand the distribution of values across the dataset.

"""

# Only numeric columns
numeric_cols = white.select_dtypes(include=np.number)

# Plot boxplots for all numeric columns
plt.figure(figsize=(12, 6))
sns.boxplot(data=numeric_cols)
plt.xticks(rotation=45)
plt.title('Boxplots of All Numeric Features')
plt.show()

"""## 🧾 Preview of the First 20 Rows of the Dataset
Viewing the first 20 rows to inspect the data and ensure that all preprocessing steps are correctly applied.

"""

white.head(20)

"""## 🔖 Creating Binary Quality Labels
We convert the `quality` column into a binary classification by setting:
- **Good wine**: `quality >= 5` → label as 1
- **Not good wine**: `quality < 5` → label as 0

"""

# Create binary label# one good wine 0 bad wine
white['quality_label'] = (white['quality'] >= 5).astype(int)

"""## 🧾 Preview of the Updated Dataset
After creating the binary quality labels, we can inspect the updated dataset to ensure everything is correct.

"""

white

"""## 🧑‍💻 Splitting the Data into Training and Testing Sets
We split the data into **features (X)** and **target (y)**. The dataset is divided into **80% training** and **20% testing** sets to evaluate model performance.

"""

from sklearn.model_selection import train_test_split

# Features (X) and target (y)
features = ['alcohol', 'density', 'volatile acidity', 'chlorides', 'total sulfur dioxide']
X = white[features]
y = white['quality_label']

# Train-test split (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## 🤖 Training the Logistic Regression Model
We train a logistic regression model using the training data and evaluate its performance on the test set. The evaluation includes the confusion matrix and classification report for precision, recall, F1-score, and accuracy.

"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""## 📝 Predicting Wine Quality Based on User Input
We allow the user to input values for key features such as alcohol content, density, and acidity. The model then predicts whether the wine is **good** or **not good** based on these inputs.

"""

# Collect input from the user
alcohol = float(input("Enter alcohol content: "))
density = float(input("Enter density: "))
volatile_acidity = float(input("Enter volatile acidity: "))
chlorides = float(input("Enter chlorides: "))
total_sulfur_dioxide = float(input("Enter total sulfur dioxide: "))

# Combine into an array
user_input = np.array([[alcohol, density, volatile_acidity, chlorides, total_sulfur_dioxide]])

# Predict using the trained model
prediction = model.predict(user_input)

# Show result
if prediction[0] == 1:
    print("✅ The wine is predicted to be GOOD.")
else:
    print("❌ The wine is predicted to be NOT GOOD.")

"""## 📈 Model Accuracy
We evaluate the model’s performance by calculating the accuracy on both the training and test sets. This gives us an understanding of how well the model generalizes to unseen data.

"""

from sklearn.metrics import accuracy_score

# Predict on training data
y_train_pred = model.predict(X_train)

# Predict on test data
y_test_pred = model.predict(X_test)

# Accuracy on train and test sets
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"✅ Train Accuracy: {train_accuracy * 100:.2f}%")
print(f"✅ Test Accuracy: {test_accuracy * 100:.2f}%")